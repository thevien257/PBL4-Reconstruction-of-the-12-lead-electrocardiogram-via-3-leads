{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG 12-Lead Reconstruction from 3 Leads\n",
    "\n",
    "**Paper**: [AI-enhanced reconstruction of the 12-lead electrocardiogram via 3-leads with accurate clinical assessment](https://www.nature.com/articles/s41746-024-01193-7)\n",
    "\n",
    "Mason, F., Pandey, A.C., Gadaleta, M. et al. npj Digit. Med. 7, 201 (2024)\n",
    "\n",
    "## Key Findings from Paper:\n",
    "- **Input**: 3 leads (I, II, V3) are sufficient to reconstruct full 12-lead ECG\n",
    "- **Output**: Reconstructs precordial leads (V1-V6) with high correlation\n",
    "- **Performance**: AUC = 0.95 for acute MI detection\n",
    "- **Clinical validation**: 81.4% accuracy in identifying STEMI features\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Setup** - Import libraries and configure settings\n",
    "2. **Data Processing** - Prepare and split the dataset\n",
    "3. **Training** - Train the reconstruction model\n",
    "4. **Testing** - Evaluate model performance\n",
    "5. **Visualization** - Plot results and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n",
      "CUDA available: False\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    DEVICE = 'cuda:0'\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION (Based on Paper)\n",
      "============================================================\n",
      "\n",
      "Input leads:  limb+v3 → I, II, V3 (3 leads)\n",
      "Output leads: precordial → V1, V2, V3, V4, V5, V6 (6 leads)\n",
      "\n",
      "Network: ResCNN with residual connections\n",
      "  - Input depth:  3 blocks\n",
      "  - Middle depth: 2 blocks\n",
      "  - Output depth: 3 blocks\n",
      "  - Channels: 32\n",
      "  - Kernel size: 17\n",
      "\n",
      "Training:\n",
      "  - Epochs: 200\n",
      "  - Batch size: 16\n",
      "  - Learning rate: 3e-06\n",
      "  - Optimizer: adam\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Based on Paper (Nature s41746-024-01193-7)\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Device\n",
    "    'device': DEVICE,\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # INPUT/OUTPUT LEADS (Paper: I + II + V3 → V1-V6)\n",
    "    # ---------------------------------------------------------\n",
    "    'input_leads': 'limb+v3',     # Paper uses: I, II, V3 (3 leads)\n",
    "    'output_leads': 'precordial', # Paper reconstructs: V1, V2, V3, V4, V5, V6 (6 leads)\n",
    "    \n",
    "    # Dataset\n",
    "    'dataset': 'infarct+noninfarct',  # Paper focuses on MI detection\n",
    "    'data_size': 'max',               # Paper used ~600,000 ECGs\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # NETWORK ARCHITECTURE (Paper: ResCNN blocks)\n",
    "    # ---------------------------------------------------------\n",
    "    # Input network: 3 ResCNN blocks (one per input lead)\n",
    "    # Middle network: 1 ResCNN block (aggregates features)  \n",
    "    # Output network: 6 ResCNN blocks (one per output lead)\n",
    "    'input_channel': 32,\n",
    "    'middle_channel': 32,\n",
    "    'output_channel': 32,\n",
    "    'input_depth': 3,      # 3 ResCNN blocks for input\n",
    "    'middle_depth': 2,     # Middle processing blocks\n",
    "    'output_depth': 3,     # 3 ResCNN blocks for output\n",
    "    'input_kernel': 17,\n",
    "    'middle_kernel': 17,\n",
    "    'output_kernel': 17,\n",
    "    'use_residual': 'true',  # Paper uses residual connections\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # TRAINING PARAMETERS\n",
    "    # ---------------------------------------------------------\n",
    "    'epoch_num': 200,\n",
    "    'batch_size': 16,\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.000003,  # 3e-6\n",
    "    'weight_decay': 0.001,\n",
    "    'momentum': 0.9,\n",
    "    'nesterov': 'true',\n",
    "    'prioritize_percent': 0,\n",
    "    'prioritize_size': 0,\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION (Based on Paper)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nInput leads:  {CONFIG['input_leads']} → I, II, V3 (3 leads)\")\n",
    "print(f\"Output leads: {CONFIG['output_leads']} → V1, V2, V3, V4, V5, V6 (6 leads)\")\n",
    "print(f\"\\nNetwork: ResCNN with residual connections\")\n",
    "print(f\"  - Input depth:  {CONFIG['input_depth']} blocks\")\n",
    "print(f\"  - Middle depth: {CONFIG['middle_depth']} blocks\")\n",
    "print(f\"  - Output depth: {CONFIG['output_depth']} blocks\")\n",
    "print(f\"  - Channels: {CONFIG['input_channel']}\")\n",
    "print(f\"  - Kernel size: {CONFIG['input_kernel']}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  - Epochs: {CONFIG['epoch_num']}\")\n",
    "print(f\"  - Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  - Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  - Optimizer: {CONFIG['optimizer']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Reconstruction Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1803192575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutil_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_parent_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_lead_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_reconstruction_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReconstructionManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparent_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_parent_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'util_functions'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from util_functions.general import get_parent_folder, get_data_classes, get_lead_keys\n",
    "from training_functions.single_reconstruction_manager import ReconstructionManager\n",
    "\n",
    "# Get settings\n",
    "parent_folder = get_parent_folder()\n",
    "data_classes = get_data_classes(CONFIG['dataset'])\n",
    "sub_classes = []\n",
    "\n",
    "# Show lead configuration\n",
    "input_keys = get_lead_keys(CONFIG['input_leads'])\n",
    "output_keys = get_lead_keys(CONFIG['output_leads'])\n",
    "print(f\"Input leads ({len(input_keys)}): {input_keys}\")\n",
    "print(f\"Output leads ({len(output_keys)}): {output_keys}\")\n",
    "print(f\"Data classes: {data_classes}\")\n",
    "print(f\"Data folder: {parent_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Reconstruction Manager\n",
    "manager = ReconstructionManager(\n",
    "    parent_folder=parent_folder,\n",
    "    device=CONFIG['device'],\n",
    "    sub_classes=sub_classes,\n",
    "    input_leads=CONFIG['input_leads'],\n",
    "    output_leads=CONFIG['output_leads'],\n",
    "    data_classes=data_classes,\n",
    "    data_size=CONFIG['data_size'],\n",
    "    input_channel=CONFIG['input_channel'],\n",
    "    middle_channel=CONFIG['middle_channel'],\n",
    "    output_channel=CONFIG['output_channel'],\n",
    "    input_depth=CONFIG['input_depth'],\n",
    "    middle_depth=CONFIG['middle_depth'],\n",
    "    output_depth=CONFIG['output_depth'],\n",
    "    input_kernel=CONFIG['input_kernel'],\n",
    "    middle_kernel=CONFIG['middle_kernel'],\n",
    "    output_kernel=CONFIG['output_kernel'],\n",
    "    use_residual=CONFIG['use_residual'],\n",
    "    epoch_num=CONFIG['epoch_num'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    prioritize_percent=CONFIG['prioritize_percent'],\n",
    "    prioritize_size=CONFIG['prioritize_size'],\n",
    "    optimizer=CONFIG['optimizer'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    momentum=CONFIG['momentum'],\n",
    "    nesterov=CONFIG['nesterov']\n",
    ")\n",
    "\n",
    "print(\"Reconstruction Manager initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "Train the deep learning model to reconstruct 12-lead ECG from input leads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset/Initialize the model\n",
    "print(\"Initializing model...\")\n",
    "manager.reset_model()\n",
    "print(\"Model initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation datasets\n",
    "print(\"Loading training and validation datasets...\")\n",
    "manager.load_dataset(train=True, valid=True)\n",
    "print(\"Datasets loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(f\"Starting training for {CONFIG['epoch_num']} epochs...\")\n",
    "print(\"=\"*50)\n",
    "manager.train()\n",
    "print(\"=\"*50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release dataset memory\n",
    "manager.release_dataset()\n",
    "print(\"Dataset memory released.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training statistics\n",
    "print(\"Plotting training statistics...\")\n",
    "manager.plot_train_stats()\n",
    "manager.plot_valid_stats()\n",
    "print(\"Training plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "print(\"Loading trained model...\")\n",
    "manager.load_model()\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "print(\"Loading test dataset...\")\n",
    "manager.load_dataset(test=True)\n",
    "print(\"Test dataset loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run testing\n",
    "print(\"Running tests...\")\n",
    "manager.test()\n",
    "print(\"Testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release test dataset memory\n",
    "manager.release_dataset()\n",
    "print(\"Test dataset memory released.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test statistics\n",
    "print(\"Plotting test statistics...\")\n",
    "manager.plot_test_stats(plot_sub_classes=sub_classes)\n",
    "print(\"Test plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "Visualize reconstruction examples and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for visualization\n",
    "manager.load_model()\n",
    "\n",
    "# Plot random reconstruction examples\n",
    "print(\"Plotting random reconstruction examples...\")\n",
    "manager.plot_random_example(plot_format='png')\n",
    "print(\"Random examples saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error examples (worst reconstructions)\n",
    "print(\"Plotting error examples...\")\n",
    "manager.load_test_stats()\n",
    "manager.plot_error_example(plot_format='png')\n",
    "print(\"Error examples saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and plot model statistics\n",
    "print(\"Computing model statistics...\")\n",
    "manager.compute_model_stats()\n",
    "manager.plot_model_stats()\n",
    "print(\"Model statistics saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Run (All in One)\n",
    "\n",
    "Run the complete pipeline in one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(config):\n",
    "    \"\"\"Run the complete training and testing pipeline.\"\"\"\n",
    "    from util_functions.general import get_parent_folder, get_data_classes\n",
    "    from training_functions.single_reconstruction_manager import ReconstructionManager\n",
    "    \n",
    "    # Initialize\n",
    "    parent_folder = get_parent_folder()\n",
    "    data_classes = get_data_classes(config['dataset'])\n",
    "    \n",
    "    manager = ReconstructionManager(\n",
    "        parent_folder=parent_folder,\n",
    "        device=config['device'],\n",
    "        sub_classes=[],\n",
    "        input_leads=config['input_leads'],\n",
    "        output_leads=config['output_leads'],\n",
    "        data_classes=data_classes,\n",
    "        data_size=config['data_size'],\n",
    "        input_channel=config['input_channel'],\n",
    "        middle_channel=config['middle_channel'],\n",
    "        output_channel=config['output_channel'],\n",
    "        input_depth=config['input_depth'],\n",
    "        middle_depth=config['middle_depth'],\n",
    "        output_depth=config['output_depth'],\n",
    "        input_kernel=config['input_kernel'],\n",
    "        middle_kernel=config['middle_kernel'],\n",
    "        output_kernel=config['output_kernel'],\n",
    "        use_residual=config['use_residual'],\n",
    "        epoch_num=config['epoch_num'],\n",
    "        batch_size=config['batch_size'],\n",
    "        prioritize_percent=config['prioritize_percent'],\n",
    "        prioritize_size=config['prioritize_size'],\n",
    "        optimizer=config['optimizer'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        momentum=config['momentum'],\n",
    "        nesterov=config['nesterov']\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TRAINING\")\n",
    "    print(\"=\" * 50)\n",
    "    manager.reset_model()\n",
    "    manager.load_dataset(train=True, valid=True)\n",
    "    manager.train()\n",
    "    manager.release_dataset()\n",
    "    manager.plot_train_stats()\n",
    "    manager.plot_valid_stats()\n",
    "    \n",
    "    # Test\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"TESTING\")\n",
    "    print(\"=\" * 50)\n",
    "    manager.load_model()\n",
    "    manager.load_dataset(test=True)\n",
    "    manager.test()\n",
    "    manager.release_dataset()\n",
    "    manager.plot_test_stats()\n",
    "    \n",
    "    # Visualize\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"VISUALIZATION\")\n",
    "    print(\"=\" * 50)\n",
    "    manager.plot_random_example()\n",
    "    manager.load_test_stats()\n",
    "    manager.plot_error_example()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"PIPELINE COMPLETED!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return manager\n",
    "\n",
    "# Uncomment to run the full pipeline:\n",
    "# manager = run_full_pipeline(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alternative: Using Command Line Scripts\n",
    "\n",
    "You can also run the scripts directly from command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reconstruction training and testing via command line\n",
    "# Uncomment to execute:\n",
    "\n",
    "# !python single_reconstruction.py -device cuda:0 -input limb -output precordial -train -test -plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classification training\n",
    "# Uncomment to execute:\n",
    "\n",
    "# !python single_classification.py -device cuda:0 -input limb -train -test -plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run combined reconstruction + classification\n",
    "# Uncomment to execute:\n",
    "\n",
    "# !python single_recon_classif.py -device cuda:0 -input limb -output precordial -train -test -plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output Lead Options Reference\n",
    "\n",
    "| Configuration | Leads | Count |\n",
    "|---------------|-------|-------|\n",
    "| `limb` | I, II | 2 |\n",
    "| `limb+v1` | I, II, V1 | 3 |\n",
    "| `limb+v2` | I, II, V2 | 3 |\n",
    "| `limb+v3` | I, II, V3 | 3 |\n",
    "| `limb+v4` | I, II, V4 | 3 |\n",
    "| `limb+v5` | I, II, V5 | 3 |\n",
    "| `limb+v6` | I, II, V6 | 3 |\n",
    "| `full_limb` | I, II, III, aVL, aVR, aVF | 6 |\n",
    "| `precordial` | V1, V2, V3, V4, V5, V6 | 6 |\n",
    "| `full` | I, II, V1, V2, V3, V4, V5, V6 | 8 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
